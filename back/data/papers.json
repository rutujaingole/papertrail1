[
  {
    "id": 1757841878862.425,
    "title": "How to Compute Using Quantum Walks",
    "authors": "Viv Kendon",
    "abstract": "Quantum walks are widely and successfully used to model diverse physical\nprocesses. This leads to computation of the models, to explore their\nproperties. Quantum walks have also been shown to be universal for quantum\ncomputing. This is a more subtle result than is often appreciated, since it\napplies to computations run on qubit-based quantum computers in the single\nwalker case, and physical quantum walks in the multi-walker case (quantum\ncellular automata). Nonetheless, quantum walks are powerful tools for quantum\ncomputing when correctly applied. In this paper, I explain the relationship\nbetween quantum walks as models and quantum walks as computational tools, and\ngive some examples of their application in both contexts.",
    "year": 2020,
    "venue": "arXiv",
    "topic": "quantum computing",
    "arxiv_id": "2004.01329v1",
    "upload_date": "2025-09-14T09:24:38.862Z",
    "is_selected": false
  },
  {
    "id": 1757841878881.703,
    "title": "Combinatorial Optimization with Quantum Computers",
    "authors": "Francisco Chicano, Gabiel Luque, Zakaria Abdelmoiz Dahi, Rodrigo Gil-Merino",
    "abstract": "Quantum computers leverage the principles of quantum mechanics to do\ncomputation with a potential advantage over classical computers. While a single\nclassical computer transforms one particular binary input into an output after\napplying one operator to the input, a quantum computer can apply the operator\nto a superposition of binary strings to provide a superposition of binary\noutputs, doing computation apparently in parallel. This feature allows quantum\ncomputers to speed up the computation compared to classical algorithms.\nUnsurprisingly, quantum algorithms have been proposed to solve optimization\nproblems in quantum computers. Furthermore, a family of quantum machines called\nquantum annealers are specially designed to solve optimization problems. In\nthis paper, we provide an introduction to quantum optimization from a practical\npoint of view. We introduce the reader to the use of quantum annealers and\nquantum gate-based machines to solve optimization problems.",
    "year": 2024,
    "venue": "arXiv",
    "topic": "quantum computing",
    "arxiv_id": "2412.15778v2",
    "upload_date": "2025-09-14T09:24:38.881Z",
    "is_selected": false
  },
  {
    "id": 1757841878951.853,
    "title": "A practicable guide to the quantum computation architectures",
    "authors": "Hou Ian, Biao Chen, Wei Zhao",
    "abstract": "The primordial model of quantum computation was introduced over thirty years\nago and the first quantum algorithms have appeared for over twenty years. Yet\nthe exact architectures for quantum computer seem foreign to an undergraduate\nstudent major in computer science or engineering, even though the mass media\nhas helped popularize the terminologies in the past decade. Despite being a\ncutting-edge technology from both the theoretical and the experimental\nperspectives, quantum computation is indeed imminent and it would be helpful to\ngive the undergraduate students at least a skeleton understanding of what a\nquantum computer stands for. Since instruction-set architectures originated\nfrom classical computing models are familiar, we propose analogously a set of\nquantum instructions, which can be composed to implement renowned quantum\nalgorithms. Albeit the similarity one can draw between classical and quantum\ncomputer architectures, current quantum instructions are fundamentally\nincommensurable from their classical counterparts because they lack the innate\ncapability to implement logical deductions and recursions. We discuss this\ntrait in length and illustrate why it is held responsible that current quantum\ncomputers not be considered general computers.",
    "year": 2019,
    "venue": "arXiv",
    "topic": "quantum computing",
    "arxiv_id": "1903.10739v2",
    "upload_date": "2025-09-14T09:24:38.951Z",
    "is_selected": false
  },
  {
    "id": 1757841878991.9714,
    "title": "Towards Distributed Quantum Computing by Qubit and Gate Graph\n  Partitioning Techniques",
    "authors": "Marc Grau Davis, Joaquin Chung, Dirk Englund, Rajkumar Kettimuthu",
    "abstract": "Distributed quantum computing is motivated by the difficulty in building\nlarge-scale, individual quantum computers. To solve that problem, a large\nquantum circuit is partitioned and distributed to small quantum computers for\nexecution. Partitions running on different quantum computers share quantum\ninformation using entangled Bell pairs. However, entanglement generation and\npurification introduces both a runtime and memory overhead on distributed\nquantum computing. In this paper we study that trade-off by proposing two\ntechniques for partitioning large quantum circuits and for distribution to\nsmall quantum computers. Our techniques map a quantum circuit to a graph\nrepresentation. We study two approaches: one that considers only gate\nteleportation, and another that considers both gate and state teleportation to\nachieve the distributed execution. Then we apply the METIS graph partitioning\nalgorithm to obtain the partitions and the number of entanglement requests\nbetween them. We use the SeQUeNCe quantum communication simulator to measure\nthe time required for generating all the entanglements required to execute the\ndistributed circuit. We find that the best partitioning technique will depend\non the specific circuit of interest.",
    "year": 2023,
    "venue": "arXiv",
    "topic": "quantum computing",
    "arxiv_id": "2310.03942v1",
    "upload_date": "2025-09-14T09:24:38.991Z",
    "is_selected": false
  },
  {
    "id": 1757841878998.5156,
    "title": "iQuantum: A Case for Modeling and Simulation of Quantum Computing\n  Environments",
    "authors": "Hoa T. Nguyen, Muhammad Usman, Rajkumar Buyya",
    "abstract": "Today's quantum computers are primarily accessible through the cloud and\npotentially shifting to the edge network in the future. With the rapid\nadvancement and proliferation of quantum computing research worldwide, there\nhas been a considerable increase in demand for using cloud-based quantum\ncomputation resources. This demand has highlighted the need for designing\nefficient and adaptable resource management strategies and service models for\nquantum computing. However, the limited quantity, quality, and accessibility of\nquantum resources pose significant challenges to practical research in quantum\nsoftware and systems. To address these challenges, we propose iQuantum, a\nfirst-of-its-kind simulation toolkit that can model hybrid quantum-classical\ncomputing environments for prototyping and evaluating system design and\nscheduling algorithms. This paper presents the quantum computing system model,\narchitectural design, proof-of-concept implementation, potential use cases, and\nfuture development of iQuantum. Our proposed iQuantum simulator is anticipated\nto boost research in quantum software and systems, particularly in the creation\nand evaluation of policies and algorithms for resource management, job\nscheduling, and hybrid quantum-classical task orchestration in quantum\ncomputing environments integrating edge and cloud resources.",
    "year": 2023,
    "venue": "arXiv",
    "topic": "quantum computing",
    "arxiv_id": "2303.15729v1",
    "upload_date": "2025-09-14T09:24:38.998Z",
    "is_selected": false
  },
  {
    "id": 1757841879000.776,
    "title": "CutQC: Using Small Quantum Computers for Large Quantum Circuit\n  Evaluations",
    "authors": "Wei Tang, Teague Tomesh, Martin Suchara, Jeffrey Larson, Margaret Martonosi",
    "abstract": "Quantum computing (QC) is a new paradigm offering the potential of\nexponential speedups over classical computing for certain computational\nproblems. Each additional qubit doubles the size of the computational state\nspace available to a QC algorithm. This exponential scaling underlies QC's\npower, but today's Noisy Intermediate-Scale Quantum (NISQ) devices face\nsignificant engineering challenges in scalability. The set of quantum circuits\nthat can be reliably run on NISQ devices is limited by their noisy operations\nand low qubit counts.\n  This paper introduces CutQC, a scalable hybrid computing approach that\ncombines classical computers and quantum computers to enable evaluation of\nquantum circuits that cannot be run on classical or quantum computers alone.\nCutQC cuts large quantum circuits into smaller subcircuits, allowing them to be\nexecuted on smaller quantum devices. Classical postprocessing can then\nreconstruct the output of the original circuit. This approach offers\nsignificant runtime speedup compared with the only viable current\nalternative--purely classical simulations--and demonstrates evaluation of\nquantum circuits that are larger than the limit of QC or classical simulation.\nFurthermore, in real-system runs, CutQC achieves much higher quantum circuit\nevaluation fidelity using small prototype quantum computers than the\nstate-of-the-art large NISQ devices achieve. Overall, this hybrid approach\nallows users to leverage classical and quantum computing resources to evaluate\nquantum programs far beyond the reach of either one alone.",
    "year": 2020,
    "venue": "arXiv",
    "topic": "quantum computing",
    "arxiv_id": "2012.02333v3",
    "upload_date": "2025-09-14T09:24:39.000Z",
    "is_selected": false
  },
  {
    "id": 1757841879002.628,
    "title": "DisQ: A Novel Quantum Output State Classification Method on IBM Quantum\n  Computers using OpenPulse",
    "authors": "Tirthak Patel, Devesh Tiwari",
    "abstract": "Superconducting quantum computing technology has ushered in a new era of\ncomputational possibilities. While a considerable research effort has been\ngeared toward improving the quantum technology and building the software stack\nto efficiently execute quantum algorithms with reduced error rate, effort\ntoward optimizing how quantum output states are defined and classified for the\npurpose of reducing the error rate is still limited. To this end, this paper\nproposes DisQ, a quantum output state classification approach which reduces\nerror rates of quantum programs on NISQ devices.",
    "year": 2021,
    "venue": "arXiv",
    "topic": "quantum computing",
    "arxiv_id": "2102.01153v1",
    "upload_date": "2025-09-14T09:24:39.002Z",
    "is_selected": false
  },
  {
    "id": 1757841879003.063,
    "title": "Enhancing quantum computer performance via symmetrization",
    "authors": "Andrii Maksymov, Jason Nguyen, Yunseong Nam, Igor Markov",
    "abstract": "Large quantum computers promise to solve some critical problems not solvable\notherwise. However, modern quantum technologies suffer various imperfections\nsuch as control errors and qubit decoherence, inhibiting their potential\nutility. The overheads of quantum error correction are too great for near-term\nquantum computers, whereas error-mitigation strategies that address specific\ndevice imperfections may lose relevance as devices improve. To enhance the\nperformance of quantum computers with high-quality qubits, we introduce a\nstrategy based on symmetrization and nonlinear aggregation. On a commercial\ntrapped-ion quantum computer, it improves performance of multiple practical\nalgorithms by 100x with no qubit or gate overhead.",
    "year": 2023,
    "venue": "arXiv",
    "topic": "quantum computing",
    "arxiv_id": "2301.07233v1",
    "upload_date": "2025-09-14T09:24:39.003Z",
    "is_selected": false
  },
  {
    "id": 1757841879005.6382,
    "title": "Techniques for Automated Machine Learning",
    "authors": "Yi-Wei Chen, Qingquan Song, Xia Hu",
    "abstract": "Automated machine learning (AutoML) aims to find optimal machine learning\nsolutions automatically given a machine learning problem. It could release the\nburden of data scientists from the multifarious manual tuning process and\nenable the access of domain experts to the off-the-shelf machine learning\nsolutions without extensive experience. In this paper, we review the current\ndevelopments of AutoML in terms of three categories, automated feature\nengineering (AutoFE), automated model and hyperparameter learning (AutoMHL),\nand automated deep learning (AutoDL). State-of-the-art techniques adopted in\nthe three categories are presented, including Bayesian optimization,\nreinforcement learning, evolutionary algorithm, and gradient-based approaches.\nWe summarize popular AutoML frameworks and conclude with current open\nchallenges of AutoML.",
    "year": 2019,
    "venue": "arXiv",
    "topic": "machine learning",
    "arxiv_id": "1907.08908v1",
    "upload_date": "2025-09-14T09:24:39.005Z",
    "is_selected": false
  },
  {
    "id": 1757841879006.0498,
    "title": "A comprehensive review of Quantum Machine Learning: from NISQ to Fault\n  Tolerance",
    "authors": "Yunfei Wang, Junyu Liu",
    "abstract": "Quantum machine learning, which involves running machine learning algorithms\non quantum devices, has garnered significant attention in both academic and\nbusiness circles. In this paper, we offer a comprehensive and unbiased review\nof the various concepts that have emerged in the field of quantum machine\nlearning. This includes techniques used in Noisy Intermediate-Scale Quantum\n(NISQ) technologies and approaches for algorithms compatible with\nfault-tolerant quantum computing hardware. Our review covers fundamental\nconcepts, algorithms, and the statistical learning theory pertinent to quantum\nmachine learning.",
    "year": 2024,
    "venue": "arXiv",
    "topic": "machine learning",
    "arxiv_id": "2401.11351v2",
    "upload_date": "2025-09-14T09:24:39.006Z",
    "is_selected": false
  },
  {
    "id": 1757841879007.5574,
    "title": "Temporal-related Convolutional-Restricted-Boltzmann-Machine capable of\n  learning relational order via reinforcement learning procedure?",
    "authors": "Zizhuang Wang",
    "abstract": "In this article, we extend the conventional framework of\nconvolutional-Restricted-Boltzmann-Machine to learn highly abstract features\namong abitrary number of time related input maps by constructing a layer of\nmultiplicative units, which capture the relations among inputs. In many cases,\nmore than two maps are strongly related, so it is wise to make multiplicative\nunit learn relations among more input maps, in other words, to find the optimal\nrelational-order of each unit. In order to enable our machine to learn\nrelational order, we developed a reinforcement-learning method whose optimality\nis proven to train the network.",
    "year": 2017,
    "venue": "arXiv",
    "topic": "machine learning",
    "arxiv_id": "1706.08001v1",
    "upload_date": "2025-09-14T09:24:39.007Z",
    "is_selected": false
  },
  {
    "id": 1757841879008.1545,
    "title": "Can Machines Learn the True Probabilities?",
    "authors": "Jinsook Kim",
    "abstract": "When there exists uncertainty, AI machines are designed to make decisions so\nas to reach the best expected outcomes. Expectations are based on true facts\nabout the objective environment the machines interact with, and those facts can\nbe encoded into AI models in the form of true objective probability functions.\nAccordingly, AI models involve probabilistic machine learning in which the\nprobabilities should be objectively interpreted. We prove under some basic\nassumptions when machines can learn the true objective probabilities, if any,\nand when machines cannot learn them.",
    "year": 2024,
    "venue": "arXiv",
    "topic": "machine learning",
    "arxiv_id": "2407.05526v1",
    "upload_date": "2025-09-14T09:24:39.008Z",
    "is_selected": false
  },
  {
    "id": 1757841879010.9001,
    "title": "Towards A Rigorous Science of Interpretable Machine Learning",
    "authors": "Finale Doshi-Velez, Been Kim",
    "abstract": "As machine learning systems become ubiquitous, there has been a surge of\ninterest in interpretable machine learning: systems that provide explanation\nfor their outputs. These explanations are often used to qualitatively assess\nother criteria such as safety or non-discrimination. However, despite the\ninterest in interpretability, there is very little consensus on what\ninterpretable machine learning is and how it should be measured. In this\nposition paper, we first define interpretability and describe when\ninterpretability is needed (and when it is not). Next, we suggest a taxonomy\nfor rigorous evaluation and expose open questions towards a more rigorous\nscience of interpretable machine learning.",
    "year": 2017,
    "venue": "arXiv",
    "topic": "machine learning",
    "arxiv_id": "1702.08608v2",
    "upload_date": "2025-09-14T09:24:39.010Z",
    "is_selected": false
  },
  {
    "id": 1757841879011.4868,
    "title": "Techniques for Interpretable Machine Learning",
    "authors": "Mengnan Du, Ninghao Liu, Xia Hu",
    "abstract": "Interpretable machine learning tackles the important problem that humans\ncannot understand the behaviors of complex machine learning models and how\nthese models arrive at a particular decision. Although many approaches have\nbeen proposed, a comprehensive understanding of the achievements and challenges\nis still lacking. We provide a survey covering existing techniques to increase\nthe interpretability of machine learning models. We also discuss crucial issues\nthat the community should consider in future work such as designing\nuser-friendly explanations and developing comprehensive evaluation metrics to\nfurther push forward the area of interpretable machine learning.",
    "year": 2018,
    "venue": "arXiv",
    "topic": "machine learning",
    "arxiv_id": "1808.00033v3",
    "upload_date": "2025-09-14T09:24:39.011Z",
    "is_selected": false
  },
  {
    "id": 1757841879012.7683,
    "title": "On the Conditions for Domain Stability for Machine Learning: a\n  Mathematical Approach",
    "authors": "Gabriel Pedroza",
    "abstract": "This work proposes a mathematical approach that (re)defines a property of\nMachine Learning models named stability and determines sufficient conditions to\nvalidate it. Machine Learning models are represented as functions, and the\ncharacteristics in scope depend upon the domain of the function, what allows us\nto adopt topological and metric spaces theory as a basis. Finally, this work\nprovides some equivalences useful to prove and test stability in Machine\nLearning models. The results suggest that whenever stability is aligned with\nthe notion of function smoothness, then the stability of Machine Learning\nmodels primarily depends upon certain topological, measurable properties of the\nclassification sets within the ML model domain.",
    "year": 2024,
    "venue": "arXiv",
    "topic": "machine learning",
    "arxiv_id": "2412.00464v1",
    "upload_date": "2025-09-14T09:24:39.012Z",
    "is_selected": false
  },
  {
    "id": 1757841879013.3877,
    "title": "PyKale: Knowledge-Aware Machine Learning from Multiple Sources in Python",
    "authors": "Haiping Lu, Xianyuan Liu, Robert Turner, Peizhen Bai, Raivo E Koot, Shuo Zhou, Mustafa Chasmai, Lawrence Schobs",
    "abstract": "Machine learning is a general-purpose technology holding promises for many\ninterdisciplinary research problems. However, significant barriers exist in\ncrossing disciplinary boundaries when most machine learning tools are developed\nin different areas separately. We present Pykale - a Python library for\nknowledge-aware machine learning on graphs, images, texts, and videos to enable\nand accelerate interdisciplinary research. We formulate new green machine\nlearning guidelines based on standard software engineering practices and\npropose a novel pipeline-based application programming interface (API). PyKale\nfocuses on leveraging knowledge from multiple sources for accurate and\ninterpretable prediction, thus supporting multimodal learning and transfer\nlearning (particularly domain adaptation) with latest deep learning and\ndimensionality reduction models. We build PyKale on PyTorch and leverage the\nrich PyTorch ecosystem. Our pipeline-based API design enforces standardization\nand minimalism, embracing green machine learning concepts via reducing\nrepetitions and redundancy, reusing existing resources, and recycling learning\nmodels across areas. We demonstrate its interdisciplinary nature via examples\nin bioinformatics, knowledge graph, image/video recognition, and medical\nimaging.",
    "year": 2021,
    "venue": "arXiv",
    "topic": "machine learning",
    "arxiv_id": "2106.09756v1",
    "upload_date": "2025-09-14T09:24:39.013Z",
    "is_selected": false
  },
  {
    "id": 1757841879014.5293,
    "title": "Future Climate Change Projections over the Indian Region",
    "authors": "J. Sanjay, R. Krishnan, M. V. S. Ramarao, R. Mahesh, Bhupendra Bahadur Singh, Jayashri Patel, Sandip Ingle, Preethi Bhaskar, J. V. Revadekar, T. P. Sabin, M. Mujumdar",
    "abstract": "Assessments of impacts of climate change and future projections over the\nIndian region, have so far relied on a single regional climate model (RCM) -\neg., the PRECIS RCM of the Hadley Centre, UK. While these assessments have\nprovided inputs to various reports (e.g., INCCA 2010; NATCOMM2 2012), it is\nimportant to have an ensemble of climate projections drawn from multiple RCMs\ndue to large uncertainties in regional-scale climate projections. Ensembles of\nmulti-RCM projections driven under different perceivable socio-economic\nscenarios are required to capture the probable path of growth, and provide the\nbehavior of future climate and impacts on various biophysical systems and\neconomic sectors dependent on such systems.\n  The Centre for Climate Change Research, Indian Institute of Tropical\nMeteorology (CCCR-IITM) has generated an ensemble of high resolution downscaled\nprojections of regional climate and monsoon over South Asia until 2100 for the\nIntergovernmental Panel for Climate Change (IPCC)using a RCM (ICTP-RegCM4) at\n50 km horizontal resolution, by driving the regional model with lateral and\nlower boundary conditions from multiple global atmosphere-ocean coupled models\nfrom the Coupled Model Intercomparison Project Phase 5 (CMIP5). The future\nprojections are based on three Representation Concentration Pathway (RCP)\nscenarios (viz., RCP2.6, RCP4.5, RCP8.5) of the IPCC.",
    "year": 2020,
    "venue": "arXiv",
    "topic": "climate change",
    "arxiv_id": "2012.10386v1",
    "upload_date": "2025-09-14T09:24:39.014Z",
    "is_selected": false
  },
  {
    "id": 1757841879015.1047,
    "title": "Climate Prediction through Statistical Methods",
    "authors": "Bora Akgun, Zeynep Isvan, Levent Tuter, Mehmet Levent Kurnaz",
    "abstract": "Climate change is a reality of today. Paleoclimatic proxies and climate\npredictions based on coupled atmosphere-ocean general circulation models\nprovide us with temperature data. Using Detrended Fluctuation Analysis, we are\ninvestigating the statistical connection between the climate types of the\npresent and these local temperatures. We are relating this issue to some\nwell-known historic climate shifts. Our main result is that the temperature\nfluctuations with or without a temperature scale attached to them, can be used\nto classify climates in the absence of other indicators such as pan evaporation\nand precipitation.",
    "year": 2008,
    "venue": "arXiv",
    "topic": "climate change",
    "arxiv_id": "0803.0382v1",
    "upload_date": "2025-09-14T09:24:39.015Z",
    "is_selected": false
  },
  {
    "id": 1757841879016.7915,
    "title": "Offshore wind energy climate projection using UPSCALE climate data under\n  the RCP8.5 emission scenario",
    "authors": "Markus Gross, Vanesa Magar",
    "abstract": "Recently it was demonstrated how climate data can be utilized to estimate\nregional wind power densities. In particular it was shown that the quality of\nthe global scale estimate compared well with regional high resolution studies\nand a link between surface temperature and moist density in the estimate was\npresented. In the present paper the methodology is tested further, to ensure\nthat the results using one climate data set are reliable. This is achieved by\nextending the study to include four ensemble members. With the confidence that\none instantiation is sufficient a climate change data set, which was also a\nresult of the UPSCALE experiment, is analyzed. This, for the first time,\nprovides a projection of future changes in wind power resources using this data\nset. This climate change data set is based on the Representative Concentration\nPathways (RCP) 8.5 climate change scenario. This provides guidance for\ndevelopers and policy makers to mitigate and adapt.",
    "year": 2015,
    "venue": "arXiv",
    "topic": "climate change",
    "arxiv_id": "1510.02043v1",
    "upload_date": "2025-09-14T09:24:39.016Z",
    "is_selected": false
  },
  {
    "id": 1757841879018.6848,
    "title": "Emergent constraints on climate sensitivities",
    "authors": "Mark S. Williamson, Chad W. Thackeray, Peter M. Cox, Alex Hall, Chris Huntingford, Femke J. M. M. Nijsse",
    "abstract": "Despite major advances in climate science over the last 30 years, persistent\nuncertainties in projections of future climate change remain. Climate\nprojections are produced with increasingly complex models which attempt to\nrepresent key processes in the Earth system, including atmospheric and oceanic\ncirculations, convection, clouds, snow, sea-ice, vegetation and interactions\nwith the carbon cycle. Uncertainties in the representation of these processes\nfeed through into a range of projections from the many state-of-the-art climate\nmodels now being developed and used worldwide. For example, despite major\nimprovements in climate models, the range of equilibrium global warming due to\ndoubling carbon dioxide still spans a range of more than three. Here we review\na promising way to make use of the ensemble of climate models to reduce the\nuncertainties in the sensitivities of the real climate system. The emergent\nconstraint approach uses the model ensemble to identify a relationship between\nan uncertain aspect of the future climate and an observable variation or trend\nin the contemporary climate. This review summarises previous published work on\nemergent constraints, and discusses the huge promise and potential dangers of\nthe approach. Most importantly, it argues that emergent constraints should be\nbased on well-founded physical principles such as the fluctuation-dissipation\ntheorem. It is hoped that this review will stimulate physicists to contribute\nto the rapidly developing field of emergent constraints on climate projections,\nbringing to it much needed rigour and physical insights.",
    "year": 2020,
    "venue": "arXiv",
    "topic": "climate change",
    "arxiv_id": "2012.09468v1",
    "upload_date": "2025-09-14T09:24:39.018Z",
    "is_selected": false
  },
  {
    "id": 1757841879018.4937,
    "title": "Assessing the climate benefits of afforestation: processes, methods, and\n  frameworks",
    "authors": "Kevin Bradley Dsouza, Enoch Ofosu, Jack Salkeld, Richard Boudreault, Juan Moreno-Cruz, Yuri Leonenko",
    "abstract": "Afforestation greatly influences several earth system processes, making it\nessential to understand these effects to accurately assess its potential for\nclimate change mitigation. Although our understanding of forest-climate system\ninteractions has improved, significant knowledge gaps remain, preventing\ndefinitive assessments of afforestation's net climate benefits. In this review,\nfocusing on the Canadian northern boreal and southern arctic, we identify these\ngaps and synthesize existing knowledge. The review highlights regional\nrealities, Earth's climatic history, uncertainties in biogeochemical (BGC) and\nbiogeophysical (BGP) changes following afforestation, and limitations in\ncurrent assessment methodologies, emphasizing the need to reconcile these\nuncertainties before drawing firm conclusions about the climate benefits of\nafforestation. Finally, we propose an assessment framework which considers\nmultiple forcing components, temporal analysis, future climatic contexts, and\nimplementation details. We hope that the research gaps and assessment framework\ndiscussed in this review inform afforestation policy in Canada and other\ncircumpolar nations.",
    "year": 2024,
    "venue": "arXiv",
    "topic": "climate change",
    "arxiv_id": "2407.14617v3",
    "upload_date": "2025-09-14T09:24:39.018Z",
    "is_selected": false
  },
  {
    "id": 1757841879019.7305,
    "title": "Another Look at Climate Sensitivity",
    "authors": "Ilya Zaliapin, Michael Ghil",
    "abstract": "We revisit a recent claim that the Earth's climate system is characterized by\nsensitive dependence to parameters; in particular, that the system exhibits an\nasymmetric, large-amplitude response to normally distributed feedback forcing.\nSuch a response would imply irreducible uncertainty in climate change\npredictions and thus have notable implications for climate science and\nclimate-related policy making. We show that equilibrium climate sensitivity in\nall generality does not support such an intrinsic indeterminacy; the latter\nappears only in essentially linear systems. The main flaw in the analysis that\nled to this claim is inappropriate linearization of an intrinsically nonlinear\nmodel; there is no room for physical interpretations or policy conclusions\nbased on this mathematical error. Sensitive dependence nonetheless does exist\nin the climate system, as well as in climate models -- albeit in a very\ndifferent sense from the one claimed in the linear work under scrutiny -- and\nwe illustrate it using a classical energy balance model (EBM) with nonlinear\nfeedbacks. EBMs exhibit two saddle-node bifurcations, more recently called\n\"tipping points\", which give rise to three distinct steady-state climates, two\nof which are stable. Such bistable behavior is, furthermore, supported by\nresults from more realistic, nonequilibrium climate models. In a truly\nnonlinear setting, indeterminacy in the size of the response is observed only\nin the vicinity of tipping points. We show, in fact, that small disturbances\ncannot result in a large-amplitude response, unless the system is at or near\nsuch a point. We discuss briefly how the distance to the bifurcation may be\nrelated to the strength of Earth's ice-albedo feedback.",
    "year": 2010,
    "venue": "arXiv",
    "topic": "climate change",
    "arxiv_id": "1003.0253v1",
    "upload_date": "2025-09-14T09:24:39.019Z",
    "is_selected": false
  },
  {
    "id": 1757841879021.4058,
    "title": "Quantitative implications of the secondary role of carbon dioxide\n  climate forcing in the past glacial-interglacial cycles for the likely future\n  climatic impacts of anthropogenic greenhouse-gas forcings",
    "authors": "Willie Soon",
    "abstract": "A review of the recent refereed literature fails to confirm quantitatively\nthat carbon dioxide (CO2) radiative forcing was the prime mover in the changes\nin temperature, ice-sheet volume, and related climatic variables in the glacial\nand interglacial periods of the past 650,000 years, even under the \"fast\nresponse\" framework where the convenient if artificial distinction between\nforcing and feedback is assumed. Atmospheric CO2 variations generally follow\nchanges in temperature and other climatic variables rather than preceding them.\nLikewise, there is no confirmation of the often-posited significant supporting\nrole of methane (CH4) forcing, which despite its faster atmospheric response\ntime is simply too small, amounting to less than 0.2 W/m2 from a change of 400\nppb. We cannot quantitatively validate the numerous qualitative suggestions\nthat the CO2 and CH4 forcings that occurred in response to the Milankovich\norbital cycles accounted for more than half of the amplitude of the changes in\nthe glacial/interglacial cycles of global temperature, sea level, and ice\nvolume. Consequently, we infer that natural climatic variability notably the\npersistence of insolation forcing at key seasons and geographical locations,\ntaken with closely-related thermal, hydrological, and cryospheric changes (such\nas the water vapor, cloud, and ice-albedo feedbacks) suffices in se to explain\nthe proxy-derived, global and regional, climatic and environmental\nphase-transitions in the paleoclimate. If so, it may be appropriate to place\nanthropogenic greenhouse-gas emissions in context by separating their\nmedium-term climatic impacts from those of a host of natural forcings and\nfeedbacks that may, as in paleoclimatological times, prove just as significant.",
    "year": 2007,
    "venue": "arXiv",
    "topic": "climate change",
    "arxiv_id": "0707.1276v1",
    "upload_date": "2025-09-14T09:24:39.021Z",
    "is_selected": false
  },
  {
    "id": 1757841879022.599,
    "title": "Simple El Niño prediction scheme using the signature of climate time\n  series",
    "authors": "Nozomi Sugiura, Shinya Kouketsu",
    "abstract": "El Ni\\~{n}o is a typical example of a coupled atmosphere--ocean phenomenon,\nbut it is unclear whether it can be described quantitatively by a correlation\nbetween relevant climate events. To provide clarity on this issue, we developed\na machine learning-based El Ni\\~{n}o prediction model that uses the time series\nof climate indices. By transforming the multidimensional time series into the\npath signature, the model is able to properly evaluate the order and\nnonlinearity of climate events, which allowed us to achieve good forecasting\nskill (mean square error = 0.596 for 6-month prediction). In addition, it is\npossible to provide information about the sequence of climate events that tend\nto change the future NINO3.4 sea surface temperatures. In forecasting\nexperiments conducted, changes in the North Pacific Index and several NINO\nindices were found to be important precursors. The results suggest that El\nNi\\~{n}o is predictable to some extent based on the correlation of climate\nevents.",
    "year": 2021,
    "venue": "arXiv",
    "topic": "climate change",
    "arxiv_id": "2109.02013v5",
    "upload_date": "2025-09-14T09:24:39.022Z",
    "is_selected": false
  }
]